import requests
from bs4 import BeautifulSoup as bsp
import csv

# Create CSV file lists
product_url = []
UPC = []
title = []
prices_including_tax = []
prices_excluding_tax = []
number_available = []
product_description = []
category = []
review_rating = []
image_url = []

# Define the number of pages
pages = [str(i) for i in range(1, 51)]

# First loop to parse and get all the pages
for page in pages:
    # Get the URL with requests to see if site is working
    response = requests.get('http://books.toscrape.com/catalogue/page-' + page + '.html')
    # Beautifulsoup to parse
    page_html = bsp(response.text, 'html.parser')
    print(response)
    # attributes that we are looking for
    book_containers = page_html.find_all(attrs={'class': 'product_pod'})

# Second loop to seek urls of each book in the website
    for book in book_containers:
        # Url
        a = book.find('a')
        url = a['href']
        product_url.append('https://books.toscrape.com/catalogue/' + url)

# For each book
    book_url = https://books.toscrape.com /catalogue/a-light-in-the-attic_1000/index.html
    response = requests.get(book_url)
        if response.ok:
            soup = bsp(response.text, 'html.parser')
            

        # Titre
        title.append(book.h3.a.get('title'))
        # Prix with taxes
        prices_including_tax.append(book.find('p', class_="price_color").text[2:])  # Slicing price sign
        # Prix without taxes
        prices_excluding_tax
        # Number of products available
        number_available.append(book.find('p', class_="instock availability"))
        # Description
        product_description
        # Cat√©gories
        category
        # Notes
        review_rating.append(book.find("p", class_="star-rating").get("class")[1])  # To only get the number of stars
        # Url image
        image_url.append(book.find("img").get("src"))
        # print(product_url)

# CSV file creation
with open('projet2.csv', 'w', newline='') as f:
    for url in product_url:
        f.write(url + '\n')
